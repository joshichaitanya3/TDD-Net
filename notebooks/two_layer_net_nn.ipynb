{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *\n",
    "import random\n",
    "import math\n",
    "import seaborn\n",
    "from  matplotlib import pyplot\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10       # The image size = 28 x 28 = 784\n",
    "hidden_size = 80      # The number of nodes at the hidden layer\n",
    "num_classes = 5       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 50         # The number of times entire dataset is trained\n",
    "batch_size = 256       # The size of input data took for one iteration\n",
    "learning_rate = 0.01  # The speed of convergence\n",
    "non_pos_ratio = 1\n",
    "weight_decay=5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "        transforms.RandomRotation((-90,90)),\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "#         transforms.RandomRotation((-90,90)),\n",
    "#         torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "#         torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 10 (input data) -> 80 (hidden node)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 80 (hidden node) -> 5 (output class)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rliu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=10, out_features=80, bias=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (fc2): Linear(in_features=80, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.kaiming_normal(m.weight)\n",
    "net.apply(init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/ml/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/ml/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1.0, 1.0, 1.0, 1.0, 1.0/non_pos_ratio]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.0015 Acc: 0.0054 batch_loss: 15.1212 correct: 54 batch_accuracy: 0.2109\n",
      "train Loss: 0.0023 Acc: 0.0116 batch_loss: 7.7439 correct: 62 batch_accuracy: 0.2422\n",
      "train Loss: 0.0027 Acc: 0.0259 batch_loss: 4.1341 correct: 142 batch_accuracy: 0.5547\n",
      "train Loss: 0.0031 Acc: 0.0380 batch_loss: 3.5387 correct: 121 batch_accuracy: 0.4727\n",
      "train Loss: 0.0032 Acc: 0.0565 batch_loss: 1.6641 correct: 185 batch_accuracy: 0.7227\n",
      "train Loss: 0.0033 Acc: 0.0806 batch_loss: 0.4442 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0033 Acc: 0.1053 batch_loss: 0.2150 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0033 Acc: 0.1299 batch_loss: 0.1673 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0033 Acc: 0.1544 batch_loss: 0.2533 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0034 Acc: 0.1791 batch_loss: 0.2751 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0034 Acc: 0.2032 batch_loss: 0.4718 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0034 Acc: 0.2277 batch_loss: 0.3645 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0035 Acc: 0.2518 batch_loss: 0.2585 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0035 Acc: 0.2765 batch_loss: 0.1839 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0035 Acc: 0.3010 batch_loss: 0.2713 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0035 Acc: 0.3254 batch_loss: 0.2029 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0036 Acc: 0.3499 batch_loss: 0.3063 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0036 Acc: 0.3746 batch_loss: 0.1855 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0036 Acc: 0.3991 batch_loss: 0.2112 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0036 Acc: 0.4241 batch_loss: 0.1787 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0036 Acc: 0.4486 batch_loss: 0.2125 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0037 Acc: 0.4734 batch_loss: 0.1114 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0037 Acc: 0.4979 batch_loss: 0.1609 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0037 Acc: 0.5230 batch_loss: 0.1417 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0037 Acc: 0.5470 batch_loss: 0.2487 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0037 Acc: 0.5718 batch_loss: 0.2147 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0038 Acc: 0.5964 batch_loss: 0.2146 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0038 Acc: 0.6208 batch_loss: 0.4027 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0038 Acc: 0.6452 batch_loss: 0.2905 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0038 Acc: 0.6700 batch_loss: 0.2090 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0039 Acc: 0.6947 batch_loss: 0.1740 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0039 Acc: 0.7193 batch_loss: 0.2568 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0039 Acc: 0.7437 batch_loss: 0.3055 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0039 Acc: 0.7684 batch_loss: 0.0854 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0040 Acc: 0.7931 batch_loss: 0.2734 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0040 Acc: 0.8176 batch_loss: 0.2926 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0040 Acc: 0.8421 batch_loss: 0.2644 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0040 Acc: 0.8668 batch_loss: 0.1884 correct: 246 batch_accuracy: 0.9609\n",
      "Accuracy of the network on the test images: 81.14583 %\n",
      "Accuracy of   pos : 83 %\n",
      "Accuracy of   neg : 84 %\n",
      "Accuracy of pos_o : 76 %\n",
      "Accuracy of   nuc : 65 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [761.0, 778.0, 771.0, 764.0, 766.0]\n",
      "class correct:  [637.0, 654.0, 593.0, 501.0, 731.0]\n",
      "total:  3840\n",
      "correct:  3116\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0246 batch_loss: 0.2409 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0494 batch_loss: 0.1522 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.0748 batch_loss: 0.1142 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0001 Acc: 0.0990 batch_loss: 0.2062 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1240 batch_loss: 0.1544 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1485 batch_loss: 0.2188 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1725 batch_loss: 0.3916 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.1971 batch_loss: 0.2238 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.2221 batch_loss: 0.1201 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.2469 batch_loss: 0.1916 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.2717 batch_loss: 0.1855 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.2959 batch_loss: 0.2399 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.3205 batch_loss: 0.2225 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.3449 batch_loss: 0.2426 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.3698 batch_loss: 0.2047 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.3948 batch_loss: 0.1750 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.4197 batch_loss: 0.1577 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.4442 batch_loss: 0.2387 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.4688 batch_loss: 0.1870 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.4938 batch_loss: 0.1030 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.5184 batch_loss: 0.2711 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.5431 batch_loss: 0.2511 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.5677 batch_loss: 0.2444 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.5916 batch_loss: 0.3794 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0005 Acc: 0.6159 batch_loss: 0.1820 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.6403 batch_loss: 0.2274 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.6646 batch_loss: 0.4266 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0006 Acc: 0.6889 batch_loss: 0.2499 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.7136 batch_loss: 0.1727 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.7385 batch_loss: 0.1709 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0007 Acc: 0.7624 batch_loss: 0.4168 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0007 Acc: 0.7872 batch_loss: 0.1584 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0007 Acc: 0.8118 batch_loss: 0.1745 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.8367 batch_loss: 0.0938 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0008 Acc: 0.8613 batch_loss: 0.2016 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.8861 batch_loss: 0.2119 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0008 Acc: 0.9113 batch_loss: 0.0900 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0008 Acc: 0.9361 batch_loss: 0.1125 correct: 248 batch_accuracy: 0.9688\n",
      "Accuracy of the network on the test images: 82.21354 %\n",
      "Accuracy of   pos : 83 %\n",
      "Accuracy of   neg : 86 %\n",
      "Accuracy of pos_o : 78 %\n",
      "Accuracy of   nuc : 66 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [764.0, 769.0, 763.0, 772.0, 772.0]\n",
      "class correct:  [639.0, 665.0, 601.0, 516.0, 736.0]\n",
      "total:  3840\n",
      "correct:  3157\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0245 batch_loss: 0.2650 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0485 batch_loss: 0.3139 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.0730 batch_loss: 0.1918 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0980 batch_loss: 0.0950 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.1229 batch_loss: 0.1810 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1479 batch_loss: 0.1398 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1723 batch_loss: 0.1998 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.1968 batch_loss: 0.2139 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.2207 batch_loss: 0.2605 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0002 Acc: 0.2452 batch_loss: 0.2438 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.2700 batch_loss: 0.0989 correct: 247 batch_accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0003 Acc: 0.2944 batch_loss: 0.3075 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.3193 batch_loss: 0.2234 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.3444 batch_loss: 0.0725 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.3692 batch_loss: 0.0700 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.3937 batch_loss: 0.2347 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.4180 batch_loss: 0.2662 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.4425 batch_loss: 0.3063 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.4677 batch_loss: 0.1078 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.4925 batch_loss: 0.1619 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.5173 batch_loss: 0.1957 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.5421 batch_loss: 0.2012 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.5665 batch_loss: 0.1305 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.5917 batch_loss: 0.1413 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0005 Acc: 0.6170 batch_loss: 0.0639 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0005 Acc: 0.6417 batch_loss: 0.2212 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.6668 batch_loss: 0.0859 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0005 Acc: 0.6911 batch_loss: 0.2555 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.7158 batch_loss: 0.1715 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.7407 batch_loss: 0.1674 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0006 Acc: 0.7658 batch_loss: 0.1483 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0006 Acc: 0.7906 batch_loss: 0.1260 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.8148 batch_loss: 0.1631 correct: 242 batch_accuracy: 0.9453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ebb242e12c2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "best_model_wts = net.state_dict()\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    trainset = defectDataset_df(df = split_and_sample(method = 'yolo',n_samples = 1995, non_pos_ratio=non_pos_ratio), window_size = window_size,\n",
    "                                             transforms=train_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8, drop_last=True)\n",
    "    print(\"trainloader ready!\")\n",
    "\n",
    "    testset = defectDataset_df(df = split_and_sample(df_labels = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/test.csv', sep=\" \"), \n",
    "                                                     df_yolo = pd.read_csv('/home/rliu/github/defect_classifier/yolo2_dm/results/test_yolo.csv', sep=' '),\n",
    "                                            method = 'yolo',n_samples = 800), window_size = window_size, transforms=test_transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8)\n",
    "    print(\"testloader ready!\")\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    scheduler.step()\n",
    "    model_uniform.train(False)\n",
    "    model_hard.train(False)\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "        outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "        outputs_out = net(outputs_in)\n",
    "        _, preds = torch.max(outputs_out.data, 1)\n",
    "        loss = criterion(outputs_out, labels)\n",
    "\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "\n",
    "#         if (i+1) % 100 == 0:                              # Logging\n",
    "#             print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "#                  %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n",
    "\n",
    "        \n",
    "        # statistics\n",
    "        iter_loss = loss.item()\n",
    "        correct = torch.sum(preds == labels.data).item()\n",
    "        batch_accuracy = correct / batch_size\n",
    "        running_loss += loss.item()\n",
    "        running_corrects_tensor = torch.sum(preds == labels.data)\n",
    "        running_corrects += running_corrects_tensor.item()        \n",
    "        epoch_loss = running_loss / len(trainset)\n",
    "        epoch_acc = running_corrects / len(trainset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f} batch_loss: {:.4f} correct: {:d} batch_accuracy: {:.4f}'.format(\n",
    "            \"train\", epoch_loss, epoch_acc, iter_loss, correct, batch_accuracy))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(5))\n",
    "    class_total = list(0. for i in range(5))    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "            outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "            outputs_out = net(outputs_in)\n",
    "            _, predicted = torch.max(outputs_out.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(batch_size):\n",
    "                if len(labels) == batch_size:\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    correct += c[i].item()\n",
    "                    total += 1\n",
    "#             if len(labels) == batch_size:\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "    #         print(predicted)\n",
    "    #         print(labels)\n",
    "    #       print('processed: %d' % total)\n",
    "    #       print('correct: %d' % correct)\n",
    "        print('Accuracy of the network on the test images: %.5f %%' % (100 * correct / total))\n",
    "        for i in range(5):\n",
    "            print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print('class total: ',class_total)\n",
    "        print('class correct: ',class_correct)\n",
    "        print('total: ', total)\n",
    "        print('correct: ', correct)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "net.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 200, 200])\n",
      "torch.Size([256, 5])\n",
      "torch.Size([256, 10])\n",
      "torch.Size([256, 5])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(outputs_uniform.shape)\n",
    "print(outputs_in.shape)\n",
    "print(outputs_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    \n",
    "    \n",
    "batch_size = 5\n",
    "trainset = defectDataset_df(df = split_and_sample(method = 'yolo',n_samples = 1995, non_pos_ratio = non_pos_ratio), window_size = window_size, transforms=data_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                     batch_size=batch_size, shuffle=True,\n",
    "                                     num_workers=4, drop_last=True)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs_uniform = model_uniform(images)\n",
    "outputs_hard = model_hard(images)\n",
    "outputs = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-12.3108,   3.8134, -12.1610,  -8.9865, -18.6308],\n",
      "        [  4.1426, -12.6464, -16.8836, -13.2110, -13.5861],\n",
      "        [ -9.9046, -12.1545,  -9.0868,   2.3950, -12.2668],\n",
      "        [ -5.9917,   3.7852,  -9.3418, -10.6862, -11.3693],\n",
      "        [  4.1033,  -7.9563,  -6.8923, -13.0635,  -7.5087]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor([[-10.9020,   2.6503, -13.7712, -12.7975, -13.3193],\n",
      "        [  3.1850, -11.8032, -13.6199, -11.8008, -12.5677],\n",
      "        [-13.4012, -12.1915, -14.3676,   1.9575, -15.2399],\n",
      "        [ -7.2337,   2.6256, -18.3268, -10.4256,  -9.0024],\n",
      "        [  3.2153, -10.9220, -13.6908, -12.3731, -11.7074]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs_uniform)\n",
    "print(outputs_hard)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 3, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2542\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1384\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1731\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1142\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0950\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1930\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1513\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1833\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1233\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1183\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0871\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0677\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0196\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0825\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0880\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0757\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0220\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0282\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0166\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0539\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0231\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0305\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0996\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0352\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0392\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0510\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0487\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0199\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0501\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0229\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22127796709537506"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    if use_gpu:\n",
    "        print(\"GPU in use\")\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "    num_of_classes = len(classes)\n",
    "\n",
    "    model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_uniform.eval()\n",
    "    model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_hard.eval()\n",
    "    if use_gpu:\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
