{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *\n",
    "import random\n",
    "import math\n",
    "import seaborn\n",
    "from  matplotlib import pyplot\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10       # The image size = 28 x 28 = 784\n",
    "hidden_size = 100      # The number of nodes at the hidden layer\n",
    "num_classes = 5       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 256       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence\n",
    "non_pos_ratio = 10\n",
    "weight_decay=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "        transforms.RandomRotation((-90,90)),\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "#         transforms.RandomRotation((-90,90)),\n",
    "#         torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "#         torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 10 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "#         self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "#         self.fc3 = nn.Linear(hidden_size, num_classes) # 3rd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1.0, 1.0, 1.0, 1.0, 1.0/non_pos_ratio]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 0.0062 batch_loss: 4.3978 correct: 172 batch_accuracy: 0.6719\n",
      "train Loss: 0.0003 Acc: 0.0111 batch_loss: 3.2392 correct: 138 batch_accuracy: 0.5391\n",
      "train Loss: 0.0004 Acc: 0.0149 batch_loss: 3.2827 correct: 107 batch_accuracy: 0.4180\n",
      "train Loss: 0.0005 Acc: 0.0182 batch_loss: 2.7586 correct: 91 batch_accuracy: 0.3555\n",
      "train Loss: 0.0006 Acc: 0.0213 batch_loss: 2.7285 correct: 87 batch_accuracy: 0.3398\n",
      "train Loss: 0.0007 Acc: 0.0248 batch_loss: 2.3072 correct: 99 batch_accuracy: 0.3867\n",
      "train Loss: 0.0007 Acc: 0.0281 batch_loss: 2.1693 correct: 91 batch_accuracy: 0.3555\n",
      "train Loss: 0.0008 Acc: 0.0322 batch_loss: 1.8290 correct: 114 batch_accuracy: 0.4453\n",
      "train Loss: 0.0009 Acc: 0.0375 batch_loss: 1.6473 correct: 147 batch_accuracy: 0.5742\n",
      "train Loss: 0.0009 Acc: 0.0419 batch_loss: 1.4680 correct: 124 batch_accuracy: 0.4844\n",
      "train Loss: 0.0010 Acc: 0.0465 batch_loss: 1.3619 correct: 130 batch_accuracy: 0.5078\n",
      "train Loss: 0.0010 Acc: 0.0511 batch_loss: 1.4298 correct: 126 batch_accuracy: 0.4922\n",
      "train Loss: 0.0011 Acc: 0.0544 batch_loss: 1.3749 correct: 92 batch_accuracy: 0.3594\n",
      "train Loss: 0.0011 Acc: 0.0581 batch_loss: 1.2508 correct: 104 batch_accuracy: 0.4062\n",
      "train Loss: 0.0012 Acc: 0.0617 batch_loss: 1.1926 correct: 102 batch_accuracy: 0.3984\n",
      "train Loss: 0.0012 Acc: 0.0661 batch_loss: 1.0465 correct: 123 batch_accuracy: 0.4805\n",
      "train Loss: 0.0012 Acc: 0.0714 batch_loss: 0.9840 correct: 147 batch_accuracy: 0.5742\n",
      "train Loss: 0.0013 Acc: 0.0769 batch_loss: 1.0541 correct: 154 batch_accuracy: 0.6016\n",
      "train Loss: 0.0013 Acc: 0.0827 batch_loss: 0.9195 correct: 163 batch_accuracy: 0.6367\n",
      "train Loss: 0.0013 Acc: 0.0889 batch_loss: 0.8544 correct: 172 batch_accuracy: 0.6719\n",
      "train Loss: 0.0014 Acc: 0.0950 batch_loss: 0.9104 correct: 169 batch_accuracy: 0.6602\n",
      "train Loss: 0.0014 Acc: 0.1019 batch_loss: 0.8236 correct: 195 batch_accuracy: 0.7617\n",
      "train Loss: 0.0014 Acc: 0.1088 batch_loss: 0.8367 correct: 191 batch_accuracy: 0.7461\n",
      "train Loss: 0.0015 Acc: 0.1158 batch_loss: 0.7786 correct: 197 batch_accuracy: 0.7695\n",
      "train Loss: 0.0015 Acc: 0.1233 batch_loss: 0.7591 correct: 210 batch_accuracy: 0.8203\n",
      "train Loss: 0.0015 Acc: 0.1309 batch_loss: 0.7574 correct: 211 batch_accuracy: 0.8242\n",
      "train Loss: 0.0015 Acc: 0.1382 batch_loss: 0.7441 correct: 205 batch_accuracy: 0.8008\n",
      "train Loss: 0.0016 Acc: 0.1464 batch_loss: 0.6324 correct: 227 batch_accuracy: 0.8867\n",
      "train Loss: 0.0016 Acc: 0.1548 batch_loss: 0.6692 correct: 235 batch_accuracy: 0.9180\n",
      "train Loss: 0.0016 Acc: 0.1634 batch_loss: 0.5884 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0016 Acc: 0.1715 batch_loss: 0.6293 correct: 227 batch_accuracy: 0.8867\n",
      "train Loss: 0.0016 Acc: 0.1801 batch_loss: 0.6434 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0017 Acc: 0.1887 batch_loss: 0.5433 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0017 Acc: 0.1972 batch_loss: 0.5101 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0017 Acc: 0.2054 batch_loss: 0.5137 correct: 230 batch_accuracy: 0.8984\n",
      "train Loss: 0.0017 Acc: 0.2141 batch_loss: 0.5167 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0017 Acc: 0.2225 batch_loss: 0.4817 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0018 Acc: 0.2310 batch_loss: 0.4878 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0018 Acc: 0.2395 batch_loss: 0.4755 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0018 Acc: 0.2481 batch_loss: 0.4418 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0018 Acc: 0.2566 batch_loss: 0.4247 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0018 Acc: 0.2652 batch_loss: 0.4181 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0018 Acc: 0.2735 batch_loss: 0.4966 correct: 232 batch_accuracy: 0.9062\n",
      "train Loss: 0.0019 Acc: 0.2820 batch_loss: 0.4428 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0019 Acc: 0.2908 batch_loss: 0.3822 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0019 Acc: 0.2993 batch_loss: 0.3964 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0019 Acc: 0.3076 batch_loss: 0.4521 correct: 232 batch_accuracy: 0.9062\n",
      "train Loss: 0.0019 Acc: 0.3163 batch_loss: 0.3697 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0019 Acc: 0.3248 batch_loss: 0.3815 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0019 Acc: 0.3333 batch_loss: 0.3633 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0020 Acc: 0.3417 batch_loss: 0.4142 correct: 235 batch_accuracy: 0.9180\n",
      "train Loss: 0.0020 Acc: 0.3501 batch_loss: 0.3403 correct: 235 batch_accuracy: 0.9180\n",
      "train Loss: 0.0020 Acc: 0.3586 batch_loss: 0.4185 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0020 Acc: 0.3673 batch_loss: 0.3109 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0020 Acc: 0.3760 batch_loss: 0.3452 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0020 Acc: 0.3847 batch_loss: 0.2993 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0020 Acc: 0.3934 batch_loss: 0.2968 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0020 Acc: 0.4021 batch_loss: 0.2908 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0020 Acc: 0.4111 batch_loss: 0.2925 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0021 Acc: 0.4196 batch_loss: 0.2977 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0021 Acc: 0.4284 batch_loss: 0.2624 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0021 Acc: 0.4370 batch_loss: 0.3352 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0021 Acc: 0.4458 batch_loss: 0.2759 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0021 Acc: 0.4545 batch_loss: 0.2681 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0021 Acc: 0.4631 batch_loss: 0.2575 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0021 Acc: 0.4716 batch_loss: 0.3091 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0021 Acc: 0.4801 batch_loss: 0.2657 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0021 Acc: 0.4889 batch_loss: 0.2829 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0021 Acc: 0.4976 batch_loss: 0.2451 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0022 Acc: 0.5059 batch_loss: 0.3088 correct: 233 batch_accuracy: 0.9102\n",
      "train Loss: 0.0022 Acc: 0.5146 batch_loss: 0.2785 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0022 Acc: 0.5234 batch_loss: 0.2225 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0022 Acc: 0.5322 batch_loss: 0.2739 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0022 Acc: 0.5406 batch_loss: 0.2871 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0022 Acc: 0.5492 batch_loss: 0.2600 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0022 Acc: 0.5579 batch_loss: 0.2620 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0022 Acc: 0.5666 batch_loss: 0.2317 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0022 Acc: 0.5751 batch_loss: 0.2575 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0022 Acc: 0.5840 batch_loss: 0.2188 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0022 Acc: 0.5927 batch_loss: 0.2617 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0023 Acc: 0.6013 batch_loss: 0.2289 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0023 Acc: 0.6100 batch_loss: 0.2140 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0023 Acc: 0.6188 batch_loss: 0.2104 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0023 Acc: 0.6275 batch_loss: 0.2170 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0023 Acc: 0.6359 batch_loss: 0.2750 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0023 Acc: 0.6444 batch_loss: 0.2188 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0023 Acc: 0.6531 batch_loss: 0.2213 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0023 Acc: 0.6617 batch_loss: 0.2461 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0023 Acc: 0.6703 batch_loss: 0.2197 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0023 Acc: 0.6790 batch_loss: 0.2026 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0023 Acc: 0.6878 batch_loss: 0.2294 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0023 Acc: 0.6964 batch_loss: 0.2111 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0024 Acc: 0.7050 batch_loss: 0.2414 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0024 Acc: 0.7135 batch_loss: 0.2954 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0024 Acc: 0.7222 batch_loss: 0.2175 correct: 244 batch_accuracy: 0.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0024 Acc: 0.7307 batch_loss: 0.2291 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0024 Acc: 0.7393 batch_loss: 0.2151 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0024 Acc: 0.7481 batch_loss: 0.2452 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0024 Acc: 0.7569 batch_loss: 0.2396 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0024 Acc: 0.7656 batch_loss: 0.1902 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0024 Acc: 0.7743 batch_loss: 0.2648 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0024 Acc: 0.7830 batch_loss: 0.1645 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0024 Acc: 0.7917 batch_loss: 0.2061 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0024 Acc: 0.8004 batch_loss: 0.1739 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0025 Acc: 0.8088 batch_loss: 0.2428 correct: 233 batch_accuracy: 0.9102\n",
      "train Loss: 0.0025 Acc: 0.8176 batch_loss: 0.1732 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0025 Acc: 0.8264 batch_loss: 0.1774 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0025 Acc: 0.8352 batch_loss: 0.1734 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0025 Acc: 0.8440 batch_loss: 0.1852 correct: 244 batch_accuracy: 0.9531\n",
      "Accuracy of the network on the test images: 83.80208 %\n",
      "Accuracy of   pos : 85 %\n",
      "Accuracy of   neg : 88 %\n",
      "Accuracy of pos_o : 78 %\n",
      "Accuracy of   nuc : 71 %\n",
      "Accuracy of   non : 93 %\n",
      "class total:  [767.0, 763.0, 774.0, 773.0, 763.0]\n",
      "class correct:  [658.0, 679.0, 610.0, 554.0, 717.0]\n",
      "total:  3840\n",
      "correct:  3218\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0087 batch_loss: 0.1595 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0175 batch_loss: 0.1805 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0261 batch_loss: 0.1920 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0000 Acc: 0.0348 batch_loss: 0.1821 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0436 batch_loss: 0.1875 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0525 batch_loss: 0.1828 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0610 batch_loss: 0.1696 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.0698 batch_loss: 0.1659 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0784 batch_loss: 0.1826 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.0872 batch_loss: 0.1559 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0958 batch_loss: 0.2016 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.1046 batch_loss: 0.1708 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1131 batch_loss: 0.2329 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.1220 batch_loss: 0.1503 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1308 batch_loss: 0.1358 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1395 batch_loss: 0.1742 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1479 batch_loss: 0.1645 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0001 Acc: 0.1566 batch_loss: 0.2286 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1654 batch_loss: 0.1909 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1741 batch_loss: 0.1466 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1827 batch_loss: 0.2270 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.1914 batch_loss: 0.2140 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2002 batch_loss: 0.1662 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.2090 batch_loss: 0.1265 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.2177 batch_loss: 0.2378 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.2264 batch_loss: 0.1547 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.2351 batch_loss: 0.1488 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.2439 batch_loss: 0.1686 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.2525 batch_loss: 0.1891 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.2611 batch_loss: 0.2176 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.2697 batch_loss: 0.2249 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.2785 batch_loss: 0.1626 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.2872 batch_loss: 0.1978 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.2957 batch_loss: 0.1759 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0002 Acc: 0.3044 batch_loss: 0.1449 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3133 batch_loss: 0.1859 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3220 batch_loss: 0.2327 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3306 batch_loss: 0.2256 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.3392 batch_loss: 0.1901 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.3478 batch_loss: 0.2166 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.3564 batch_loss: 0.2358 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.3649 batch_loss: 0.1882 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.3735 batch_loss: 0.1357 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.3823 batch_loss: 0.1623 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.3912 batch_loss: 0.1228 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.3999 batch_loss: 0.1890 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.4087 batch_loss: 0.1417 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.4173 batch_loss: 0.1897 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.4258 batch_loss: 0.2031 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.4346 batch_loss: 0.1692 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.4431 batch_loss: 0.1687 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0003 Acc: 0.4517 batch_loss: 0.1383 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.4603 batch_loss: 0.2131 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.4688 batch_loss: 0.1934 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0004 Acc: 0.4774 batch_loss: 0.1938 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.4862 batch_loss: 0.1621 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.4947 batch_loss: 0.1807 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0004 Acc: 0.5034 batch_loss: 0.1465 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.5121 batch_loss: 0.1252 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.5210 batch_loss: 0.1042 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.5298 batch_loss: 0.1240 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.5386 batch_loss: 0.1429 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.5472 batch_loss: 0.1478 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.5560 batch_loss: 0.1228 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.5648 batch_loss: 0.1177 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.5735 batch_loss: 0.1336 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.5821 batch_loss: 0.1610 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.5908 batch_loss: 0.1725 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.5995 batch_loss: 0.1295 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.6080 batch_loss: 0.1747 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0004 Acc: 0.6167 batch_loss: 0.1749 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6255 batch_loss: 0.1611 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.6343 batch_loss: 0.1277 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.6428 batch_loss: 0.1604 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0005 Acc: 0.6511 batch_loss: 0.1894 correct: 232 batch_accuracy: 0.9062\n",
      "train Loss: 0.0005 Acc: 0.6596 batch_loss: 0.2103 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0005 Acc: 0.6683 batch_loss: 0.1089 correct: 245 batch_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0005 Acc: 0.6770 batch_loss: 0.1652 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0005 Acc: 0.6859 batch_loss: 0.1082 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.6944 batch_loss: 0.1819 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0005 Acc: 0.7029 batch_loss: 0.1547 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0005 Acc: 0.7116 batch_loss: 0.1967 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.7203 batch_loss: 0.1367 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.7290 batch_loss: 0.1284 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.7376 batch_loss: 0.1646 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0005 Acc: 0.7462 batch_loss: 0.1667 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0005 Acc: 0.7547 batch_loss: 0.1528 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0005 Acc: 0.7633 batch_loss: 0.1860 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0005 Acc: 0.7721 batch_loss: 0.1431 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.7807 batch_loss: 0.1419 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0006 Acc: 0.7892 batch_loss: 0.1824 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0006 Acc: 0.7980 batch_loss: 0.1298 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.8068 batch_loss: 0.1254 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.8157 batch_loss: 0.0972 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.8245 batch_loss: 0.1079 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.8333 batch_loss: 0.1247 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.8419 batch_loss: 0.1244 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0006 Acc: 0.8506 batch_loss: 0.1559 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.8595 batch_loss: 0.1442 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.8681 batch_loss: 0.2284 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0006 Acc: 0.8769 batch_loss: 0.0929 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.8856 batch_loss: 0.1537 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.8944 batch_loss: 0.1740 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.9031 batch_loss: 0.0996 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.9119 batch_loss: 0.1131 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.9207 batch_loss: 0.1525 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.9294 batch_loss: 0.1267 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.9381 batch_loss: 0.1410 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0006 Acc: 0.9465 batch_loss: 0.1976 correct: 235 batch_accuracy: 0.9180\n",
      "Accuracy of the network on the test images: 84.03646 %\n",
      "Accuracy of   pos : 85 %\n",
      "Accuracy of   neg : 91 %\n",
      "Accuracy of pos_o : 76 %\n",
      "Accuracy of   nuc : 72 %\n",
      "Accuracy of   non : 94 %\n",
      "class total:  [769.0, 769.0, 767.0, 764.0, 771.0]\n",
      "class correct:  [654.0, 705.0, 586.0, 553.0, 729.0]\n",
      "total:  3840\n",
      "correct:  3227\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0086 batch_loss: 0.1386 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0000 Acc: 0.0172 batch_loss: 0.1400 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0000 Acc: 0.0259 batch_loss: 0.1776 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0346 batch_loss: 0.1302 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0432 batch_loss: 0.1695 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0000 Acc: 0.0521 batch_loss: 0.1436 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0606 batch_loss: 0.1560 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0000 Acc: 0.0694 batch_loss: 0.1175 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0780 batch_loss: 0.1682 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.0868 batch_loss: 0.1103 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0956 batch_loss: 0.2007 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1043 batch_loss: 0.1728 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1130 batch_loss: 0.1090 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1216 batch_loss: 0.1652 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.1302 batch_loss: 0.1701 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1389 batch_loss: 0.1303 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1476 batch_loss: 0.1297 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1564 batch_loss: 0.1401 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1651 batch_loss: 0.2133 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1737 batch_loss: 0.1376 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.1822 batch_loss: 0.1663 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.1910 batch_loss: 0.1212 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1996 batch_loss: 0.1587 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.2084 batch_loss: 0.1217 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2171 batch_loss: 0.1697 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2258 batch_loss: 0.1329 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2345 batch_loss: 0.1540 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2431 batch_loss: 0.1441 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.2518 batch_loss: 0.1443 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.2605 batch_loss: 0.1096 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.2692 batch_loss: 0.1610 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.2778 batch_loss: 0.1219 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.2865 batch_loss: 0.1028 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.2951 batch_loss: 0.1234 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3038 batch_loss: 0.1295 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3126 batch_loss: 0.0769 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3212 batch_loss: 0.1289 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3300 batch_loss: 0.0760 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3386 batch_loss: 0.1700 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3473 batch_loss: 0.1932 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3559 batch_loss: 0.1288 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3646 batch_loss: 0.1774 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3733 batch_loss: 0.1818 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3820 batch_loss: 0.1513 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3904 batch_loss: 0.1769 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0002 Acc: 0.3991 batch_loss: 0.1221 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.4077 batch_loss: 0.1502 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.4164 batch_loss: 0.1743 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.4252 batch_loss: 0.1274 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.4338 batch_loss: 0.1356 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.4427 batch_loss: 0.1311 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.4515 batch_loss: 0.0769 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.4604 batch_loss: 0.1109 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.4691 batch_loss: 0.1800 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.4778 batch_loss: 0.1131 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.4861 batch_loss: 0.2060 correct: 234 batch_accuracy: 0.9141\n",
      "train Loss: 0.0003 Acc: 0.4947 batch_loss: 0.1921 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5034 batch_loss: 0.1390 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.5122 batch_loss: 0.0842 correct: 245 batch_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0003 Acc: 0.5211 batch_loss: 0.0848 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.5299 batch_loss: 0.0963 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5388 batch_loss: 0.1166 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5475 batch_loss: 0.0992 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5564 batch_loss: 0.0856 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.5651 batch_loss: 0.1267 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5738 batch_loss: 0.1169 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5826 batch_loss: 0.1507 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5911 batch_loss: 0.1109 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.5998 batch_loss: 0.1493 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6086 batch_loss: 0.0967 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.6174 batch_loss: 0.1590 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.6264 batch_loss: 0.1067 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.6351 batch_loss: 0.1467 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.6437 batch_loss: 0.1701 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0004 Acc: 0.6523 batch_loss: 0.1215 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.6610 batch_loss: 0.1876 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.6696 batch_loss: 0.2020 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.6783 batch_loss: 0.1783 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.6869 batch_loss: 0.1384 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.6957 batch_loss: 0.1579 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.7045 batch_loss: 0.1269 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.7133 batch_loss: 0.1295 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7220 batch_loss: 0.1423 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.7308 batch_loss: 0.1348 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.7395 batch_loss: 0.1607 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.7482 batch_loss: 0.1541 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7569 batch_loss: 0.1408 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7657 batch_loss: 0.1501 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.7744 batch_loss: 0.1312 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.7830 batch_loss: 0.2254 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0005 Acc: 0.7917 batch_loss: 0.1394 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0005 Acc: 0.8004 batch_loss: 0.1360 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0005 Acc: 0.8093 batch_loss: 0.0732 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0005 Acc: 0.8180 batch_loss: 0.1263 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.8267 batch_loss: 0.1159 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0005 Acc: 0.8354 batch_loss: 0.1225 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.8444 batch_loss: 0.0935 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0005 Acc: 0.8532 batch_loss: 0.1235 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.8620 batch_loss: 0.1319 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.8707 batch_loss: 0.0799 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.8794 batch_loss: 0.1263 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.8882 batch_loss: 0.1312 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.8971 batch_loss: 0.0865 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.9056 batch_loss: 0.1664 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0005 Acc: 0.9144 batch_loss: 0.1235 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.9231 batch_loss: 0.1215 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.9320 batch_loss: 0.1042 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.9407 batch_loss: 0.1444 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.9493 batch_loss: 0.1282 correct: 240 batch_accuracy: 0.9375\n",
      "Accuracy of the network on the test images: 84.14062 %\n",
      "Accuracy of   pos : 87 %\n",
      "Accuracy of   neg : 90 %\n",
      "Accuracy of pos_o : 76 %\n",
      "Accuracy of   nuc : 71 %\n",
      "Accuracy of   non : 94 %\n",
      "class total:  [766.0, 760.0, 772.0, 773.0, 769.0]\n",
      "class correct:  [670.0, 690.0, 589.0, 555.0, 727.0]\n",
      "total:  3840\n",
      "correct:  3231\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0088 batch_loss: 0.1489 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0173 batch_loss: 0.1450 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0000 Acc: 0.0262 batch_loss: 0.1348 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0000 Acc: 0.0349 batch_loss: 0.1131 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0000 Acc: 0.0437 batch_loss: 0.1697 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0526 batch_loss: 0.0932 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0613 batch_loss: 0.1276 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0698 batch_loss: 0.1758 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0000 Acc: 0.0785 batch_loss: 0.1654 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0873 batch_loss: 0.1137 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.0960 batch_loss: 0.0980 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1048 batch_loss: 0.1114 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1135 batch_loss: 0.1008 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1222 batch_loss: 0.1256 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1311 batch_loss: 0.1179 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1399 batch_loss: 0.1150 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1488 batch_loss: 0.1090 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1576 batch_loss: 0.1260 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1662 batch_loss: 0.1018 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1749 batch_loss: 0.1294 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1836 batch_loss: 0.1307 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1924 batch_loss: 0.1176 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2011 batch_loss: 0.1098 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2099 batch_loss: 0.1194 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2187 batch_loss: 0.1026 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2274 batch_loss: 0.1936 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.2361 batch_loss: 0.0998 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2448 batch_loss: 0.1516 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.2533 batch_loss: 0.1744 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0001 Acc: 0.2620 batch_loss: 0.1819 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.2708 batch_loss: 0.1074 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2794 batch_loss: 0.1552 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.2879 batch_loss: 0.1728 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0002 Acc: 0.2966 batch_loss: 0.1187 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3054 batch_loss: 0.1327 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3140 batch_loss: 0.1883 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3227 batch_loss: 0.1690 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3313 batch_loss: 0.2144 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3397 batch_loss: 0.2043 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0002 Acc: 0.3484 batch_loss: 0.1051 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3572 batch_loss: 0.0910 correct: 246 batch_accuracy: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0002 Acc: 0.3659 batch_loss: 0.1060 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3748 batch_loss: 0.0950 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.3835 batch_loss: 0.1368 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3922 batch_loss: 0.1377 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4008 batch_loss: 0.1269 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.4097 batch_loss: 0.1046 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.4185 batch_loss: 0.0939 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4273 batch_loss: 0.0792 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.4362 batch_loss: 0.1047 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.4450 batch_loss: 0.1339 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.4537 batch_loss: 0.0999 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.4623 batch_loss: 0.1645 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.4710 batch_loss: 0.1000 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.4798 batch_loss: 0.1444 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.4883 batch_loss: 0.1570 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.4970 batch_loss: 0.1199 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.5058 batch_loss: 0.1137 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.5144 batch_loss: 0.1324 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5232 batch_loss: 0.0927 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.5320 batch_loss: 0.1162 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5408 batch_loss: 0.0868 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.5493 batch_loss: 0.1580 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0003 Acc: 0.5579 batch_loss: 0.1541 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5667 batch_loss: 0.1029 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.5753 batch_loss: 0.1748 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5842 batch_loss: 0.0943 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.5931 batch_loss: 0.1239 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.6019 batch_loss: 0.1151 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.6106 batch_loss: 0.1393 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6192 batch_loss: 0.1697 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.6281 batch_loss: 0.0972 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.6370 batch_loss: 0.0696 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.6457 batch_loss: 0.1314 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6545 batch_loss: 0.1707 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.6634 batch_loss: 0.1008 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.6720 batch_loss: 0.1167 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0004 Acc: 0.6807 batch_loss: 0.1862 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6894 batch_loss: 0.1016 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.6981 batch_loss: 0.1185 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7067 batch_loss: 0.1170 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0004 Acc: 0.7153 batch_loss: 0.1240 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.7239 batch_loss: 0.1485 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.7326 batch_loss: 0.1035 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7414 batch_loss: 0.1030 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.7501 batch_loss: 0.1350 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7587 batch_loss: 0.1324 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7675 batch_loss: 0.1219 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7764 batch_loss: 0.1356 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.7850 batch_loss: 0.1026 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7938 batch_loss: 0.0831 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.8026 batch_loss: 0.0947 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8114 batch_loss: 0.1130 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8202 batch_loss: 0.0754 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.8289 batch_loss: 0.2307 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.8377 batch_loss: 0.0944 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8467 batch_loss: 0.0666 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.8552 batch_loss: 0.1589 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0005 Acc: 0.8640 batch_loss: 0.1272 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.8726 batch_loss: 0.1677 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0005 Acc: 0.8813 batch_loss: 0.1107 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.8899 batch_loss: 0.1480 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0005 Acc: 0.8986 batch_loss: 0.1422 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.9075 batch_loss: 0.0940 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.9162 batch_loss: 0.1900 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.9250 batch_loss: 0.1318 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.9335 batch_loss: 0.1288 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0005 Acc: 0.9423 batch_loss: 0.1428 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.9511 batch_loss: 0.1706 correct: 246 batch_accuracy: 0.9609\n",
      "Accuracy of the network on the test images: 84.58333 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 88 %\n",
      "Accuracy of pos_o : 77 %\n",
      "Accuracy of   nuc : 73 %\n",
      "Accuracy of   non : 96 %\n",
      "class total:  [769.0, 760.0, 766.0, 769.0, 776.0]\n",
      "class correct:  [665.0, 675.0, 597.0, 564.0, 747.0]\n",
      "total:  3840\n",
      "correct:  3248\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0087 batch_loss: 0.0928 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0174 batch_loss: 0.1019 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0261 batch_loss: 0.1014 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0000 Acc: 0.0348 batch_loss: 0.1352 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0435 batch_loss: 0.1084 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0000 Acc: 0.0522 batch_loss: 0.1338 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0608 batch_loss: 0.1483 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0000 Acc: 0.0696 batch_loss: 0.0982 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0784 batch_loss: 0.1605 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0870 batch_loss: 0.1007 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0000 Acc: 0.0958 batch_loss: 0.0940 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.1045 batch_loss: 0.1044 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1133 batch_loss: 0.1049 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1219 batch_loss: 0.1289 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1305 batch_loss: 0.1954 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.1392 batch_loss: 0.1004 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1480 batch_loss: 0.0937 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1567 batch_loss: 0.1372 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1656 batch_loss: 0.0877 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1744 batch_loss: 0.0699 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1832 batch_loss: 0.0726 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1920 batch_loss: 0.1069 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2008 batch_loss: 0.1095 correct: 247 batch_accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0001 Acc: 0.2097 batch_loss: 0.0791 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2184 batch_loss: 0.0945 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2269 batch_loss: 0.1449 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.2357 batch_loss: 0.0944 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2445 batch_loss: 0.1865 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2531 batch_loss: 0.0887 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2617 batch_loss: 0.1677 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2703 batch_loss: 0.0981 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0001 Acc: 0.2792 batch_loss: 0.0764 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.2879 batch_loss: 0.0916 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2967 batch_loss: 0.0916 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.3054 batch_loss: 0.1650 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.3143 batch_loss: 0.0888 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.3228 batch_loss: 0.1531 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0002 Acc: 0.3317 batch_loss: 0.1094 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.3404 batch_loss: 0.1102 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3492 batch_loss: 0.0864 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3579 batch_loss: 0.1445 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3668 batch_loss: 0.0690 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.3754 batch_loss: 0.1728 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.3842 batch_loss: 0.0847 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3931 batch_loss: 0.0895 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.4019 batch_loss: 0.2059 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4107 batch_loss: 0.0794 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4197 batch_loss: 0.0793 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.4283 batch_loss: 0.1129 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.4371 batch_loss: 0.1538 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4459 batch_loss: 0.0778 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4546 batch_loss: 0.1323 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4632 batch_loss: 0.1150 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.4720 batch_loss: 0.0764 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4806 batch_loss: 0.1236 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.4894 batch_loss: 0.1178 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4982 batch_loss: 0.0941 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.5067 batch_loss: 0.1256 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.5154 batch_loss: 0.1494 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.5242 batch_loss: 0.1086 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.5328 batch_loss: 0.1320 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5416 batch_loss: 0.1621 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5502 batch_loss: 0.1447 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.5591 batch_loss: 0.0737 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5676 batch_loss: 0.1742 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.5763 batch_loss: 0.0863 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5849 batch_loss: 0.1445 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5936 batch_loss: 0.1485 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6020 batch_loss: 0.1854 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0003 Acc: 0.6107 batch_loss: 0.1001 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6194 batch_loss: 0.1336 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6282 batch_loss: 0.1094 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6369 batch_loss: 0.1159 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6456 batch_loss: 0.1062 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6544 batch_loss: 0.1265 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6632 batch_loss: 0.0887 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6718 batch_loss: 0.0969 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.6807 batch_loss: 0.0838 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.6896 batch_loss: 0.0672 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.6985 batch_loss: 0.0915 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.7073 batch_loss: 0.1030 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.7161 batch_loss: 0.0848 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.7251 batch_loss: 0.0898 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.7340 batch_loss: 0.0877 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.7428 batch_loss: 0.1120 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7517 batch_loss: 0.1566 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.7604 batch_loss: 0.1127 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7691 batch_loss: 0.1186 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7778 batch_loss: 0.1089 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.7865 batch_loss: 0.1892 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7954 batch_loss: 0.0877 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.8042 batch_loss: 0.0809 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.8128 batch_loss: 0.1368 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.8216 batch_loss: 0.0890 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8305 batch_loss: 0.0762 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.8390 batch_loss: 0.2008 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0004 Acc: 0.8477 batch_loss: 0.1300 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8564 batch_loss: 0.1491 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.8652 batch_loss: 0.0668 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8740 batch_loss: 0.1129 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8828 batch_loss: 0.1170 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.8915 batch_loss: 0.1132 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.9003 batch_loss: 0.0893 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.9090 batch_loss: 0.1187 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.9179 batch_loss: 0.0681 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.9267 batch_loss: 0.1965 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.9354 batch_loss: 0.1128 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.9443 batch_loss: 0.1153 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.9532 batch_loss: 0.0795 correct: 247 batch_accuracy: 0.9648\n",
      "Accuracy of the network on the test images: 84.27083 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 78 %\n",
      "Accuracy of   nuc : 71 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [753.0, 765.0, 772.0, 773.0, 777.0]\n",
      "class correct:  [649.0, 684.0, 605.0, 555.0, 743.0]\n",
      "total:  3840\n",
      "correct:  3236\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0087 batch_loss: 0.0910 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0175 batch_loss: 0.1139 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0264 batch_loss: 0.1497 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0352 batch_loss: 0.1216 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0440 batch_loss: 0.1033 correct: 245 batch_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0000 Acc: 0.0529 batch_loss: 0.0634 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0617 batch_loss: 0.1132 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0702 batch_loss: 0.1274 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0000 Acc: 0.0790 batch_loss: 0.0881 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0879 batch_loss: 0.1088 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0966 batch_loss: 0.0717 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.1055 batch_loss: 0.0669 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.1142 batch_loss: 0.0957 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.1230 batch_loss: 0.0793 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1318 batch_loss: 0.1057 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1402 batch_loss: 0.1793 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0001 Acc: 0.1490 batch_loss: 0.1164 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1579 batch_loss: 0.0658 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1666 batch_loss: 0.1666 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1754 batch_loss: 0.0923 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1843 batch_loss: 0.0946 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1931 batch_loss: 0.0761 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2018 batch_loss: 0.1063 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2105 batch_loss: 0.1710 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2193 batch_loss: 0.0938 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2279 batch_loss: 0.1092 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0001 Acc: 0.2366 batch_loss: 0.1081 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2455 batch_loss: 0.0637 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.2544 batch_loss: 0.0989 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2632 batch_loss: 0.0876 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2720 batch_loss: 0.0803 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2807 batch_loss: 0.1379 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.2894 batch_loss: 0.1026 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2984 batch_loss: 0.0610 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.3073 batch_loss: 0.1006 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.3161 batch_loss: 0.1163 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.3250 batch_loss: 0.0760 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.3334 batch_loss: 0.1731 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0001 Acc: 0.3420 batch_loss: 0.0822 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3507 batch_loss: 0.2704 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3594 batch_loss: 0.1424 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3680 batch_loss: 0.0997 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3768 batch_loss: 0.1288 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3856 batch_loss: 0.1069 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3940 batch_loss: 0.2128 correct: 235 batch_accuracy: 0.9180\n",
      "train Loss: 0.0002 Acc: 0.4028 batch_loss: 0.0964 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.4116 batch_loss: 0.1386 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4203 batch_loss: 0.0702 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4289 batch_loss: 0.1063 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.4378 batch_loss: 0.0780 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.4466 batch_loss: 0.0837 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.4553 batch_loss: 0.1353 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.4641 batch_loss: 0.1616 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4727 batch_loss: 0.1431 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.4813 batch_loss: 0.1677 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.4902 batch_loss: 0.1032 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4989 batch_loss: 0.1394 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.5077 batch_loss: 0.0907 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.5164 batch_loss: 0.0909 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.5251 batch_loss: 0.1742 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.5339 batch_loss: 0.1046 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.5424 batch_loss: 0.1547 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.5512 batch_loss: 0.0828 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5599 batch_loss: 0.1910 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.5686 batch_loss: 0.1243 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.5773 batch_loss: 0.1606 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5860 batch_loss: 0.1123 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5947 batch_loss: 0.1027 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6035 batch_loss: 0.0851 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.6123 batch_loss: 0.1384 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6208 batch_loss: 0.1857 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.6297 batch_loss: 0.0670 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.6385 batch_loss: 0.0765 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6472 batch_loss: 0.1014 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6559 batch_loss: 0.1132 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6646 batch_loss: 0.1046 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6733 batch_loss: 0.1108 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6823 batch_loss: 0.0958 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.6910 batch_loss: 0.0972 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6995 batch_loss: 0.2143 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.7083 batch_loss: 0.1472 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.7172 batch_loss: 0.1153 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.7257 batch_loss: 0.1521 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.7345 batch_loss: 0.0816 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7432 batch_loss: 0.1308 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7518 batch_loss: 0.1398 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.7607 batch_loss: 0.0781 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.7694 batch_loss: 0.1003 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7781 batch_loss: 0.1686 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7868 batch_loss: 0.1514 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.7956 batch_loss: 0.1184 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8043 batch_loss: 0.0833 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8132 batch_loss: 0.0824 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.8221 batch_loss: 0.1094 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.8309 batch_loss: 0.0942 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8399 batch_loss: 0.1090 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.8485 batch_loss: 0.0938 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.8571 batch_loss: 0.1678 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.8660 batch_loss: 0.1230 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.8748 batch_loss: 0.0785 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8835 batch_loss: 0.1533 correct: 243 batch_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0004 Acc: 0.8923 batch_loss: 0.0736 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.9011 batch_loss: 0.1388 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.9099 batch_loss: 0.0790 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.9186 batch_loss: 0.1110 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9271 batch_loss: 0.1790 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0004 Acc: 0.9358 batch_loss: 0.0769 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9448 batch_loss: 0.0514 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.9534 batch_loss: 0.1267 correct: 240 batch_accuracy: 0.9375\n",
      "Accuracy of the network on the test images: 84.73958 %\n",
      "Accuracy of   pos : 87 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 78 %\n",
      "Accuracy of   nuc : 72 %\n",
      "Accuracy of   non : 96 %\n",
      "class total:  [767.0, 769.0, 766.0, 767.0, 771.0]\n",
      "class correct:  [669.0, 689.0, 599.0, 556.0, 741.0]\n",
      "total:  3840\n",
      "correct:  3254\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0086 batch_loss: 0.0860 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0000 Acc: 0.0172 batch_loss: 0.1636 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0000 Acc: 0.0261 batch_loss: 0.1291 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0348 batch_loss: 0.0815 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0435 batch_loss: 0.1249 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0524 batch_loss: 0.0740 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0612 batch_loss: 0.1090 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0700 batch_loss: 0.1546 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0788 batch_loss: 0.1050 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0876 batch_loss: 0.0518 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0964 batch_loss: 0.1100 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.1050 batch_loss: 0.0972 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.1137 batch_loss: 0.1118 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1225 batch_loss: 0.1083 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1312 batch_loss: 0.1319 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1401 batch_loss: 0.0938 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1489 batch_loss: 0.1072 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1577 batch_loss: 0.1620 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1665 batch_loss: 0.0781 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1753 batch_loss: 0.1179 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1839 batch_loss: 0.1169 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.1924 batch_loss: 0.1645 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0001 Acc: 0.2010 batch_loss: 0.1114 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2101 batch_loss: 0.0747 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0001 Acc: 0.2187 batch_loss: 0.0867 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.2274 batch_loss: 0.1129 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2363 batch_loss: 0.0624 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.2449 batch_loss: 0.1964 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0001 Acc: 0.2539 batch_loss: 0.0958 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0001 Acc: 0.2626 batch_loss: 0.1129 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2714 batch_loss: 0.0559 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2803 batch_loss: 0.0554 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2891 batch_loss: 0.0696 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2979 batch_loss: 0.0856 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.3066 batch_loss: 0.1002 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.3154 batch_loss: 0.1035 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.3241 batch_loss: 0.1141 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.3329 batch_loss: 0.0735 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.3416 batch_loss: 0.1702 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3502 batch_loss: 0.1158 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3591 batch_loss: 0.0943 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.3679 batch_loss: 0.0724 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3766 batch_loss: 0.2012 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3854 batch_loss: 0.0887 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3939 batch_loss: 0.1525 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0002 Acc: 0.4028 batch_loss: 0.0714 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.4117 batch_loss: 0.0598 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.4202 batch_loss: 0.1527 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0002 Acc: 0.4290 batch_loss: 0.0979 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4377 batch_loss: 0.1855 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.4464 batch_loss: 0.0750 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4551 batch_loss: 0.1251 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4639 batch_loss: 0.0911 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4728 batch_loss: 0.0757 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.4816 batch_loss: 0.1715 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4904 batch_loss: 0.0910 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4990 batch_loss: 0.1072 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.5078 batch_loss: 0.1283 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.5164 batch_loss: 0.2057 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.5251 batch_loss: 0.0821 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.5338 batch_loss: 0.1547 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.5424 batch_loss: 0.1504 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5513 batch_loss: 0.0899 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.5599 batch_loss: 0.1020 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.5688 batch_loss: 0.0960 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.5773 batch_loss: 0.1529 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0003 Acc: 0.5860 batch_loss: 0.0825 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5948 batch_loss: 0.1272 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6034 batch_loss: 0.1581 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6121 batch_loss: 0.0826 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6210 batch_loss: 0.0856 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.6296 batch_loss: 0.1640 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.6382 batch_loss: 0.1060 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.6471 batch_loss: 0.0623 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.6559 batch_loss: 0.0830 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6646 batch_loss: 0.2113 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6733 batch_loss: 0.1106 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6820 batch_loss: 0.1475 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6906 batch_loss: 0.1066 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6993 batch_loss: 0.1346 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.7080 batch_loss: 0.1381 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.7167 batch_loss: 0.1405 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.7254 batch_loss: 0.1544 correct: 243 batch_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0003 Acc: 0.7340 batch_loss: 0.1168 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.7426 batch_loss: 0.1394 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0004 Acc: 0.7515 batch_loss: 0.1215 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.7601 batch_loss: 0.1340 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7689 batch_loss: 0.0635 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7774 batch_loss: 0.0947 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.7863 batch_loss: 0.0968 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.7952 batch_loss: 0.2014 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.8037 batch_loss: 0.1669 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0004 Acc: 0.8126 batch_loss: 0.0784 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.8214 batch_loss: 0.0757 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.8301 batch_loss: 0.1955 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.8386 batch_loss: 0.1322 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0004 Acc: 0.8473 batch_loss: 0.0837 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8560 batch_loss: 0.0751 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.8648 batch_loss: 0.0697 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.8738 batch_loss: 0.0763 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.8825 batch_loss: 0.1287 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8913 batch_loss: 0.0884 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.9000 batch_loss: 0.1354 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9089 batch_loss: 0.0829 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.9177 batch_loss: 0.1218 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.9263 batch_loss: 0.0904 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.9351 batch_loss: 0.0668 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.9438 batch_loss: 0.1371 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9526 batch_loss: 0.0993 correct: 244 batch_accuracy: 0.9531\n",
      "Accuracy of the network on the test images: 84.11458 %\n",
      "Accuracy of   pos : 84 %\n",
      "Accuracy of   neg : 90 %\n",
      "Accuracy of pos_o : 77 %\n",
      "Accuracy of   nuc : 72 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [766.0, 772.0, 771.0, 771.0, 760.0]\n",
      "class correct:  [651.0, 697.0, 600.0, 557.0, 725.0]\n",
      "total:  3840\n",
      "correct:  3230\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0086 batch_loss: 0.1667 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0000 Acc: 0.0173 batch_loss: 0.1117 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0261 batch_loss: 0.0681 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0350 batch_loss: 0.1596 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0438 batch_loss: 0.1292 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0526 batch_loss: 0.1508 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0613 batch_loss: 0.0996 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0700 batch_loss: 0.1473 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0785 batch_loss: 0.1402 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0000 Acc: 0.0873 batch_loss: 0.1069 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.0962 batch_loss: 0.1253 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1048 batch_loss: 0.1539 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.1135 batch_loss: 0.1618 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1222 batch_loss: 0.1004 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1309 batch_loss: 0.0705 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1399 batch_loss: 0.0457 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0001 Acc: 0.1485 batch_loss: 0.1852 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.1574 batch_loss: 0.2000 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1663 batch_loss: 0.0828 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1749 batch_loss: 0.1386 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.1837 batch_loss: 0.0754 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1923 batch_loss: 0.1541 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2009 batch_loss: 0.1939 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2097 batch_loss: 0.1146 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2184 batch_loss: 0.1647 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2271 batch_loss: 0.1674 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2359 batch_loss: 0.1460 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2447 batch_loss: 0.0852 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2532 batch_loss: 0.1656 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.2622 batch_loss: 0.0784 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.2709 batch_loss: 0.0717 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2797 batch_loss: 0.1353 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2885 batch_loss: 0.0831 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.2973 batch_loss: 0.0883 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3059 batch_loss: 0.1790 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3145 batch_loss: 0.0917 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3233 batch_loss: 0.0757 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3319 batch_loss: 0.1794 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3405 batch_loss: 0.1210 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.3493 batch_loss: 0.0747 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3581 batch_loss: 0.1578 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3668 batch_loss: 0.0992 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3754 batch_loss: 0.1700 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3841 batch_loss: 0.1290 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3931 batch_loss: 0.0866 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.4019 batch_loss: 0.0721 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4105 batch_loss: 0.0825 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.4195 batch_loss: 0.0712 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.4284 batch_loss: 0.0683 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.4372 batch_loss: 0.1248 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4460 batch_loss: 0.0949 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4548 batch_loss: 0.0805 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.4636 batch_loss: 0.0939 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4723 batch_loss: 0.0875 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.4809 batch_loss: 0.1107 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.4897 batch_loss: 0.1285 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4984 batch_loss: 0.1311 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.5069 batch_loss: 0.0862 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.5156 batch_loss: 0.1713 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5242 batch_loss: 0.1205 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.5328 batch_loss: 0.1516 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5416 batch_loss: 0.0885 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5505 batch_loss: 0.0613 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.5594 batch_loss: 0.1281 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5681 batch_loss: 0.1627 correct: 243 batch_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0003 Acc: 0.5769 batch_loss: 0.0856 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.5857 batch_loss: 0.0947 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.5944 batch_loss: 0.0881 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6032 batch_loss: 0.0978 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.6121 batch_loss: 0.0691 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.6208 batch_loss: 0.1362 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.6294 batch_loss: 0.0770 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6381 batch_loss: 0.1396 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6469 batch_loss: 0.1262 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.6558 batch_loss: 0.1028 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.6646 batch_loss: 0.0865 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6731 batch_loss: 0.1623 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.6818 batch_loss: 0.1657 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.6906 batch_loss: 0.0674 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.6996 batch_loss: 0.0605 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.7081 batch_loss: 0.1112 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.7168 batch_loss: 0.1020 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.7255 batch_loss: 0.0943 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.7344 batch_loss: 0.1296 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.7434 batch_loss: 0.1079 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.7521 batch_loss: 0.1804 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7607 batch_loss: 0.1558 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.7694 batch_loss: 0.0786 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.7780 batch_loss: 0.1508 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.7868 batch_loss: 0.0914 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7955 batch_loss: 0.1549 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8043 batch_loss: 0.1030 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8130 batch_loss: 0.1200 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8217 batch_loss: 0.1491 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.8304 batch_loss: 0.1554 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8390 batch_loss: 0.1126 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.8478 batch_loss: 0.1149 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8566 batch_loss: 0.1026 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8653 batch_loss: 0.1126 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8738 batch_loss: 0.1348 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0004 Acc: 0.8825 batch_loss: 0.1384 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8911 batch_loss: 0.1190 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.8999 batch_loss: 0.1086 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9086 batch_loss: 0.0848 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9173 batch_loss: 0.1252 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.9261 batch_loss: 0.0562 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.9347 batch_loss: 0.1418 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0005 Acc: 0.9435 batch_loss: 0.1326 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.9524 batch_loss: 0.0722 correct: 249 batch_accuracy: 0.9727\n",
      "Accuracy of the network on the test images: 84.42708 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 90 %\n",
      "Accuracy of pos_o : 77 %\n",
      "Accuracy of   nuc : 72 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [768.0, 766.0, 772.0, 769.0, 765.0]\n",
      "class correct:  [661.0, 697.0, 595.0, 556.0, 733.0]\n",
      "total:  3840\n",
      "correct:  3242\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0088 batch_loss: 0.0656 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0175 batch_loss: 0.0899 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0261 batch_loss: 0.1593 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0000 Acc: 0.0350 batch_loss: 0.0902 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0438 batch_loss: 0.0678 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0525 batch_loss: 0.1042 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0613 batch_loss: 0.0668 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0700 batch_loss: 0.1183 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0788 batch_loss: 0.0986 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0875 batch_loss: 0.1434 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0961 batch_loss: 0.1789 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0000 Acc: 0.1046 batch_loss: 0.1519 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.1134 batch_loss: 0.0816 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1221 batch_loss: 0.0989 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1309 batch_loss: 0.1632 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1398 batch_loss: 0.1119 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.1487 batch_loss: 0.0743 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1576 batch_loss: 0.1017 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1663 batch_loss: 0.0800 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1751 batch_loss: 0.1643 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1841 batch_loss: 0.0783 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0001 Acc: 0.1929 batch_loss: 0.1458 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2016 batch_loss: 0.1091 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2103 batch_loss: 0.1938 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2190 batch_loss: 0.0978 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2279 batch_loss: 0.0658 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2365 batch_loss: 0.1197 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2450 batch_loss: 0.1760 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0001 Acc: 0.2537 batch_loss: 0.0858 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2624 batch_loss: 0.2099 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.2712 batch_loss: 0.1107 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2797 batch_loss: 0.1245 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.2886 batch_loss: 0.1381 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2971 batch_loss: 0.1778 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0002 Acc: 0.3055 batch_loss: 0.1896 correct: 235 batch_accuracy: 0.9180\n",
      "train Loss: 0.0002 Acc: 0.3143 batch_loss: 0.1116 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3230 batch_loss: 0.1102 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3316 batch_loss: 0.1113 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3401 batch_loss: 0.1105 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.3488 batch_loss: 0.1040 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3575 batch_loss: 0.0956 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3662 batch_loss: 0.1507 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3750 batch_loss: 0.0661 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3837 batch_loss: 0.0851 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3926 batch_loss: 0.0728 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4012 batch_loss: 0.1648 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.4100 batch_loss: 0.1234 correct: 245 batch_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0002 Acc: 0.4187 batch_loss: 0.1066 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4272 batch_loss: 0.1561 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0002 Acc: 0.4358 batch_loss: 0.1939 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.4445 batch_loss: 0.1068 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.4532 batch_loss: 0.1043 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.4618 batch_loss: 0.1302 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.4705 batch_loss: 0.0915 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.4792 batch_loss: 0.0878 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4880 batch_loss: 0.1667 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4968 batch_loss: 0.1702 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.5056 batch_loss: 0.1159 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5142 batch_loss: 0.0975 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5228 batch_loss: 0.1460 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5314 batch_loss: 0.0643 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.5400 batch_loss: 0.0869 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.5488 batch_loss: 0.0779 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5576 batch_loss: 0.0706 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5665 batch_loss: 0.0527 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.5754 batch_loss: 0.0865 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5842 batch_loss: 0.1106 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.5929 batch_loss: 0.1061 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6018 batch_loss: 0.0844 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.6105 batch_loss: 0.0706 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.6193 batch_loss: 0.0950 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.6280 batch_loss: 0.1469 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6369 batch_loss: 0.0573 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.6458 batch_loss: 0.1422 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.6545 batch_loss: 0.1127 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6633 batch_loss: 0.0743 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.6721 batch_loss: 0.1899 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6807 batch_loss: 0.1572 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6894 batch_loss: 0.1584 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.6983 batch_loss: 0.0704 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.7071 batch_loss: 0.1617 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.7160 batch_loss: 0.0655 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.7248 batch_loss: 0.0776 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.7338 batch_loss: 0.1424 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.7426 batch_loss: 0.0725 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7513 batch_loss: 0.1707 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.7600 batch_loss: 0.2022 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.7688 batch_loss: 0.1262 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7776 batch_loss: 0.0689 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7864 batch_loss: 0.0776 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7952 batch_loss: 0.0748 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8041 batch_loss: 0.0943 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.8126 batch_loss: 0.1489 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0004 Acc: 0.8214 batch_loss: 0.1047 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.8301 batch_loss: 0.1337 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8388 batch_loss: 0.2486 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8476 batch_loss: 0.0834 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8562 batch_loss: 0.1018 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.8649 batch_loss: 0.1223 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8734 batch_loss: 0.1722 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0004 Acc: 0.8822 batch_loss: 0.1169 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.8910 batch_loss: 0.0711 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.8999 batch_loss: 0.0607 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.9088 batch_loss: 0.1430 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.9175 batch_loss: 0.1322 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9262 batch_loss: 0.1370 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.9349 batch_loss: 0.1282 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0005 Acc: 0.9436 batch_loss: 0.1692 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.9525 batch_loss: 0.1416 correct: 246 batch_accuracy: 0.9609\n",
      "Accuracy of the network on the test images: 83.64583 %\n",
      "Accuracy of   pos : 84 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 77 %\n",
      "Accuracy of   nuc : 72 %\n",
      "Accuracy of   non : 94 %\n",
      "class total:  [765.0, 769.0, 763.0, 773.0, 770.0]\n",
      "class correct:  [648.0, 687.0, 590.0, 559.0, 728.0]\n",
      "total:  3840\n",
      "correct:  3212\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0088 batch_loss: 0.1554 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0178 batch_loss: 0.0460 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0000 Acc: 0.0267 batch_loss: 0.0682 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0354 batch_loss: 0.1657 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0440 batch_loss: 0.1283 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0000 Acc: 0.0526 batch_loss: 0.1490 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0000 Acc: 0.0612 batch_loss: 0.1709 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0000 Acc: 0.0699 batch_loss: 0.1098 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0787 batch_loss: 0.1221 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0873 batch_loss: 0.1154 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0000 Acc: 0.0962 batch_loss: 0.1016 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1051 batch_loss: 0.0927 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1139 batch_loss: 0.1023 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1227 batch_loss: 0.0694 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1314 batch_loss: 0.1010 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1403 batch_loss: 0.0615 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1488 batch_loss: 0.1731 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0001 Acc: 0.1575 batch_loss: 0.1279 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1664 batch_loss: 0.0980 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1751 batch_loss: 0.1568 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1837 batch_loss: 0.1853 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.1926 batch_loss: 0.0703 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2014 batch_loss: 0.0997 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2101 batch_loss: 0.0985 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2187 batch_loss: 0.1047 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0001 Acc: 0.2275 batch_loss: 0.0938 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2363 batch_loss: 0.0588 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.2450 batch_loss: 0.1456 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2537 batch_loss: 0.0988 correct: 245 batch_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0001 Acc: 0.2625 batch_loss: 0.1123 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2712 batch_loss: 0.1159 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0001 Acc: 0.2800 batch_loss: 0.1251 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2888 batch_loss: 0.1014 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2974 batch_loss: 0.1735 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.3063 batch_loss: 0.0833 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.3150 batch_loss: 0.1492 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3238 batch_loss: 0.0813 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3323 batch_loss: 0.1102 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0002 Acc: 0.3410 batch_loss: 0.1396 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3496 batch_loss: 0.1088 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3585 batch_loss: 0.1310 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.3675 batch_loss: 0.0973 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.3763 batch_loss: 0.1020 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3849 batch_loss: 0.1739 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.3934 batch_loss: 0.1062 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.4023 batch_loss: 0.0787 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.4110 batch_loss: 0.0845 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4198 batch_loss: 0.1376 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4285 batch_loss: 0.2209 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.4373 batch_loss: 0.1016 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.4463 batch_loss: 0.0661 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.4550 batch_loss: 0.1123 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4637 batch_loss: 0.1194 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4722 batch_loss: 0.1219 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0002 Acc: 0.4808 batch_loss: 0.0906 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0002 Acc: 0.4896 batch_loss: 0.1277 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4985 batch_loss: 0.0960 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.5072 batch_loss: 0.0771 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.5159 batch_loss: 0.1683 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.5247 batch_loss: 0.0909 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.5337 batch_loss: 0.0795 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.5425 batch_loss: 0.1049 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.5510 batch_loss: 0.0918 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.5596 batch_loss: 0.1306 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.5682 batch_loss: 0.2106 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5770 batch_loss: 0.1178 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5859 batch_loss: 0.0826 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.5945 batch_loss: 0.1362 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.6034 batch_loss: 0.0752 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.6123 batch_loss: 0.1042 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.6211 batch_loss: 0.0936 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6298 batch_loss: 0.1797 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6385 batch_loss: 0.1418 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6472 batch_loss: 0.0946 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6560 batch_loss: 0.0925 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.6648 batch_loss: 0.0677 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.6735 batch_loss: 0.1196 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.6823 batch_loss: 0.1057 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6910 batch_loss: 0.1319 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.7000 batch_loss: 0.0725 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.7086 batch_loss: 0.1134 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.7173 batch_loss: 0.1409 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.7260 batch_loss: 0.1111 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.7348 batch_loss: 0.1636 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.7438 batch_loss: 0.0913 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.7523 batch_loss: 0.2432 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0004 Acc: 0.7608 batch_loss: 0.0981 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0004 Acc: 0.7697 batch_loss: 0.0671 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.7785 batch_loss: 0.0896 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7873 batch_loss: 0.1626 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.7962 batch_loss: 0.0541 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.8049 batch_loss: 0.1243 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.8136 batch_loss: 0.1705 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.8224 batch_loss: 0.0782 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8312 batch_loss: 0.0679 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.8398 batch_loss: 0.1525 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.8484 batch_loss: 0.1176 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.8572 batch_loss: 0.0818 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8660 batch_loss: 0.0905 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.8747 batch_loss: 0.1059 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.8834 batch_loss: 0.1261 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.8923 batch_loss: 0.0800 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.9009 batch_loss: 0.1259 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.9098 batch_loss: 0.1022 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.9183 batch_loss: 0.1433 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0004 Acc: 0.9269 batch_loss: 0.1623 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0004 Acc: 0.9355 batch_loss: 0.1238 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.9442 batch_loss: 0.0956 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.9528 batch_loss: 0.1127 correct: 242 batch_accuracy: 0.9453\n",
      "Accuracy of the network on the test images: 83.95833 %\n",
      "Accuracy of   pos : 85 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 77 %\n",
      "Accuracy of   nuc : 72 %\n",
      "Accuracy of   non : 94 %\n",
      "class total:  [764.0, 768.0, 771.0, 771.0, 766.0]\n",
      "class correct:  [652.0, 691.0, 595.0, 560.0, 726.0]\n",
      "total:  3840\n",
      "correct:  3224\n",
      "Training complete in 21m 31s\n",
      "Best val Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "best_model_wts = net.state_dict()\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    trainset = defectDataset_df(df = split_and_sample(method = 'yolo',n_samples = 1995, non_pos_ratio=non_pos_ratio), window_size = window_size,\n",
    "                                             transforms=train_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8, drop_last=True)\n",
    "    print(\"trainloader ready!\")\n",
    "\n",
    "    testset = defectDataset_df(df = split_and_sample(df_labels = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/test.csv', sep=\" \"), \n",
    "                                                     df_yolo = pd.read_csv('/home/rliu/github/defect_classifier/yolo2_dm/results/test_yolo.csv', sep=' '),\n",
    "                                            method = 'yolo',n_samples = 800), window_size = window_size, transforms=test_transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8)\n",
    "    print(\"testloader ready!\")\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    scheduler.step()\n",
    "    model_uniform.train(False)\n",
    "    model_hard.train(False)\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "        outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "        outputs_out = net(outputs_in)\n",
    "        _, preds = torch.max(outputs_out.data, 1)\n",
    "        loss = criterion(outputs_out, labels)\n",
    "\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "\n",
    "#         if (i+1) % 100 == 0:                              # Logging\n",
    "#             print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "#                  %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n",
    "\n",
    "        \n",
    "        # statistics\n",
    "        iter_loss = loss.item()\n",
    "        correct = torch.sum(preds == labels.data).item()\n",
    "        batch_accuracy = correct / batch_size\n",
    "        running_loss += loss.item()\n",
    "        running_corrects_tensor = torch.sum(preds == labels.data)\n",
    "        running_corrects += running_corrects_tensor.item()        \n",
    "        epoch_loss = running_loss / len(trainset)\n",
    "        epoch_acc = running_corrects / len(trainset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f} batch_loss: {:.4f} correct: {:d} batch_accuracy: {:.4f}'.format(\n",
    "            \"train\", epoch_loss, epoch_acc, iter_loss, correct, batch_accuracy))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(5))\n",
    "    class_total = list(0. for i in range(5))    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "            outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "            outputs_out = net(outputs_in)\n",
    "            _, predicted = torch.max(outputs_out.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(batch_size):\n",
    "                if len(labels) == batch_size:\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    correct += c[i].item()\n",
    "                    total += 1\n",
    "#             if len(labels) == batch_size:\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "    #         print(predicted)\n",
    "    #         print(labels)\n",
    "    #       print('processed: %d' % total)\n",
    "    #       print('correct: %d' % correct)\n",
    "        print('Accuracy of the network on the test images: %.5f %%' % (100 * correct / total))\n",
    "        for i in range(5):\n",
    "            print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print('class total: ',class_total)\n",
    "        print('class correct: ',class_correct)\n",
    "        print('total: ', total)\n",
    "        print('correct: ', correct)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "net.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 200, 200])\n",
      "torch.Size([256, 5])\n",
      "torch.Size([256, 10])\n",
      "torch.Size([256, 5])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(outputs_uniform.shape)\n",
    "print(outputs_in.shape)\n",
    "print(outputs_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    \n",
    "    \n",
    "batch_size = 5\n",
    "trainset = defectDataset_df(df = split_and_sample(method = 'yolo',n_samples = 1995, non_pos_ratio = non_pos_ratio), window_size = window_size, transforms=data_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                     batch_size=batch_size, shuffle=True,\n",
    "                                     num_workers=4, drop_last=True)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs_uniform = model_uniform(images)\n",
    "outputs_hard = model_hard(images)\n",
    "outputs = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-12.3108,   3.8134, -12.1610,  -8.9865, -18.6308],\n",
      "        [  4.1426, -12.6464, -16.8836, -13.2110, -13.5861],\n",
      "        [ -9.9046, -12.1545,  -9.0868,   2.3950, -12.2668],\n",
      "        [ -5.9917,   3.7852,  -9.3418, -10.6862, -11.3693],\n",
      "        [  4.1033,  -7.9563,  -6.8923, -13.0635,  -7.5087]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor([[-10.9020,   2.6503, -13.7712, -12.7975, -13.3193],\n",
      "        [  3.1850, -11.8032, -13.6199, -11.8008, -12.5677],\n",
      "        [-13.4012, -12.1915, -14.3676,   1.9575, -15.2399],\n",
      "        [ -7.2337,   2.6256, -18.3268, -10.4256,  -9.0024],\n",
      "        [  3.2153, -10.9220, -13.6908, -12.3731, -11.7074]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs_uniform)\n",
    "print(outputs_hard)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 3, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2542\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1384\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1731\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1142\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0950\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1930\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1513\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1833\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1233\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1183\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0871\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0677\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0196\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0825\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0880\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0757\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0220\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0282\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0166\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0539\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0231\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0305\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0996\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0352\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0392\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0510\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0487\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0199\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0501\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0229\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22127796709537506"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    if use_gpu:\n",
    "        print(\"GPU in use\")\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "    num_of_classes = len(classes)\n",
    "\n",
    "    model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_uniform.eval()\n",
    "    model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_hard.eval()\n",
    "    if use_gpu:\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
